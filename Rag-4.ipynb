{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae17d2b",
   "metadata": {},
   "source": [
    "--–Install dependendies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08187ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-community langchain-chroma\n",
    "!pip install -qU langchain-text-splitters\n",
    "!pip install -qU sentence-transformers\n",
    "!pip install -qU transformers accelerate sentencepiece\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1202c5f",
   "metadata": {},
   "source": [
    "---Load Git/GitHub docs (Data collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2a0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "{'source': 'https://git-scm.com/docs/gittutorial', 'title': 'Git - gittutorial Documentation', 'language': 'en'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Git - gittutorial Documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "Trademark\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learn\n",
      "\n",
      "\n",
      "Book\n",
      "\n",
      "\n",
      "Cheat Sheet\n",
      "\n",
      "\n",
      "Videos\n",
      "\n",
      "\n",
      "External Links\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "Command Line\n",
      "\n",
      "\n",
      "GUIs\n",
      "\n",
      "\n",
      "Hosting\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Reference\n",
      "\n",
      "\n",
      "Install\n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Table of Contents\n",
      "        \n",
      "NAME \n",
      "SYNOPSIS \n",
      "DESCRIPTION \n",
      "Importing a new project \n",
      "Making changes \n",
      "Git tracks content not files \n",
      "Viewing project history \n",
      "Managing branches \n",
      "Using Git for collaboration \n",
      "Exploring history \n",
      "Next Steps \n",
      "SEE ALSO \n",
      "GIT \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " English ▾\n",
      "\n",
      "Localized v\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://git-scm.com/docs/gittutorial\",  # Git official tutorial\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "raw_docs = loader.load()\n",
    "\n",
    "print(\"Number of documents:\", len(raw_docs))\n",
    "print(raw_docs[0].metadata)\n",
    "print(raw_docs[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649b5f2",
   "metadata": {},
   "source": [
    "---Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be20e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git - gittutorial Documentation About Trademark Learn Book Cheat Sheet Videos External Links Tools Command Line GUIs Hosting Reference Install Community Table of Contents NAME SYNOPSIS DESCRIPTION Importing a new project Making changes Git tracks content not files Viewing project history Managing br\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    while \"  \" in text:\n",
    "        text = text.replace(\"  \", \" \")\n",
    "    return text\n",
    "\n",
    "for doc in raw_docs:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "print(raw_docs[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10de18d",
   "metadata": {},
   "source": [
    "---Chunk the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04f932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 32\n",
      "\n",
      "Sample chunk:\n",
      "\n",
      "Git - gittutorial Documentation About Trademark Learn Book Cheat Sheet Videos External Links Tools Command Line GUIs Hosting Reference Install Community Table of Contents NAME SYNOPSIS DESCRIPTION Importing a new project Making changes Git tracks content not files Viewing project history Managing branches Using Git for collaboration Exploring history Next Steps SEE ALSO GIT English ▾ Localized ver\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,      # size of each chunk in characters\n",
    "    chunk_overlap=200,   # overlap to keep context\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(raw_docs)\n",
    "\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"\\nSample chunk:\\n\")\n",
    "print(chunks[0].page_content[:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc14c2",
   "metadata": {},
   "source": [
    "---Embeddings (meaning → numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78095d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shilc\\AppData\\Local\\Temp\\ipykernel_27044\\1086120582.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 384\n",
      "First 5 values: [-0.07344470918178558, -0.02956530638039112, -0.043813176453113556, 0.020704641938209534, 0.05633087456226349]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# quick test\n",
    "test_vec = embedding_model.embed_query(\"What is git init?\")\n",
    "print(\"Embedding length:\", len(test_vec))\n",
    "print(\"First 5 values:\", test_vec[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f45cf",
   "metadata": {},
   "source": [
    "---Vector DB (Chroma) + basic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2b94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store created!\n",
      "\n",
      "Retrieved 3 chunks\n",
      "\n",
      "Comes Here\" $ git config --global user.email you@yourdomain.example.com Importing a new project Assume you have a tarball project.tar.gz with your initial work. You can place it under Git revision control as follows. $ tar xzf project.tar.gz $ cd project $ git init Git will reply Initialized empty Git repository in .git/ You’ve now initialized the working directory—​you may notice a new directory \n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"git_github_docs\"\n",
    ")\n",
    "\n",
    "print(\"✅ Vector store created!\")\n",
    "\n",
    "# quick search test\n",
    "query = \"How do I create a new git repository?\"\n",
    "docs_retrieved = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\nRetrieved\", len(docs_retrieved), \"chunks\\n\")\n",
    "print(docs_retrieved[0].page_content[:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3c627",
   "metadata": {},
   "source": [
    "---Retriever (nice wrapper over vector DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16048e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever returned 3 docs\n",
      "\n",
      "Comes Here\" $ git config --global user.email you@yourdomain.example.com Importing a new project Assume you have a tarball project.tar.gz with your initial work. You can place it under Git revision control as follows. $ tar xzf project.tar.gz $ cd project $ git init Git will reply Initialized empty Git repository in .git/ You’ve now initialized the working directory—​you may notice a new directory \n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "test_docs = retriever.invoke(\"What does git init do?\")\n",
    "print(\"Retriever returned\", len(test_docs), \"docs\\n\")\n",
    "print(test_docs[0].page_content[:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6236c67",
   "metadata": {},
   "source": [
    "---Load free LLM (TinyLlama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45e9e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading model (this may take a bit)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TinyLlama loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"Loading model (this may take a bit)...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"   # use GPU if Colab has it, else CPU\n",
    ")\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "print(\"✅ TinyLlama loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be908134",
   "metadata": {},
   "source": [
    "---RAG function: Retrieve + Augment + Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f12a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG function defined.\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    # Join all chunk texts with separators\n",
    "    return \"\\n\\n---\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "system_instruction = (\n",
    "    \"You are an assistant that answers questions about Git basics \"\n",
    "    \"using ONLY the context provided. \"\n",
    "    \"If the answer is not in the context, say you are not sure. \"\n",
    "    \"Give short, clear answers in 3–6 sentences. \"\n",
    "    \"Do not ask new questions or start new Q&A blocks.\"\n",
    ")\n",
    "\n",
    "def rag_answer(question: str) -> str:\n",
    "    # 1) Retrieve relevant chunks\n",
    "    docs = retriever.invoke(question)\n",
    "    context = format_docs(docs)\n",
    "\n",
    "    # 2) Build prompt for TinyLlama\n",
    "    prompt = (\n",
    "        f\"{system_instruction}\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "\n",
    "    # 3) Generate answer\n",
    "    outputs = llm_pipeline(prompt)[0][\"generated_text\"]\n",
    "\n",
    "    # 4) Keep only part after \"Answer:\"\n",
    "    text = outputs.split(\"Answer:\", 1)[-1].strip()\n",
    "\n",
    "    # If model starts adding another \"Question:\", cut it off\n",
    "    if \"Question:\" in text:\n",
    "        text = text.split(\"Question:\", 1)[0].strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "print(\"✅ RAG function defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef9eae",
   "metadata": {},
   "source": [
    "---– Test Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bccf9c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is a git hub?\n",
      "A: A git hub is a central location where you can store your git repositories.\n"
     ]
    }
   ],
   "source": [
    "#print(\"Q: What does git init do?\")\n",
    "#print(\"A:\", rag_answer(\"What does git init do?\"))\n",
    "\n",
    "#print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "#print(\"Q: What is a git commit?\")\n",
    "#print(\"A:\", rag_answer(\"What is a git commit?\"))\n",
    "\n",
    "#print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Q: What is a git hub?\")\n",
    "print(\"A:\", rag_answer(\"What is a git hub?\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
