{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5da33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp313-cp313-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from faiss-cpu) (25.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.1.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: shellingham in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\shilc\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shilc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.1)\n",
      "Downloading faiss_cpu-1.13.0-cp313-cp313-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/18.7 MB 2.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.6/18.7 MB 3.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/18.7 MB 3.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.4/18.7 MB 3.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 4.5/18.7 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 5.8/18.7 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.8/18.7 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 8.1/18.7 MB 4.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 9.7/18.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 11.0/18.7 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 12.6/18.7 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 14.2/18.7 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.7/18.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.6/18.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.8/110.9 MB 9.6 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 3.9/110.9 MB 9.8 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 6.3/110.9 MB 10.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 8.1/110.9 MB 10.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 10.5/110.9 MB 10.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 12.8/110.9 MB 10.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 15.2/110.9 MB 10.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 17.8/110.9 MB 10.9 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 20.4/110.9 MB 11.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 23.3/110.9 MB 11.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 26.2/110.9 MB 11.5 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 29.1/110.9 MB 11.6 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 32.0/110.9 MB 11.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 34.9/110.9 MB 12.0 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 38.3/110.9 MB 12.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 41.4/110.9 MB 12.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 44.3/110.9 MB 12.5 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 47.7/110.9 MB 12.7 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 51.4/110.9 MB 13.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 54.3/110.9 MB 13.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 57.7/110.9 MB 13.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 61.1/110.9 MB 13.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 64.7/110.9 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 68.4/110.9 MB 13.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.8/110.9 MB 13.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 75.5/110.9 MB 14.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 79.4/110.9 MB 14.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 83.6/110.9 MB 14.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 87.6/110.9 MB 14.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 91.5/110.9 MB 14.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 94.9/110.9 MB 14.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 99.1/110.9 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 103.3/110.9 MB 15.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 107.5/110.9 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 15.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 110.9/110.9 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 4.2/12.0 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 19.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 566.1/566.1 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 4.5/8.7 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 21.3 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.3-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.5/38.5 MB 22.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 8.9/38.5 MB 22.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 13.9/38.5 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.1/38.5 MB 22.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.4/38.5 MB 23.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 29.9/38.5 MB 23.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.5 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 23.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 25.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, networkx, joblib, faiss-cpu, torch, scikit-learn, huggingface-hub, transformers, sentence-transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 1.1.4\n",
      "    Uninstalling huggingface_hub-1.1.4:\n",
      "      Successfully uninstalled huggingface_hub-1.1.4\n",
      "Successfully installed faiss-cpu-1.13.0 huggingface-hub-0.36.0 joblib-1.5.2 networkx-3.6 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 threadpoolctl-3.6.0 torch-2.9.1 transformers-4.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu sentence-transformers numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b9ad2",
   "metadata": {},
   "source": [
    "--> Above cell is for numpy math calculations, vector DB as faiss-cpu, sentence-transformers â†’ to create embeddings (local, free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d25cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_rag.py\n",
    "\n",
    "documents = [\n",
    "    \"\"\"\n",
    "    Our company offers 20 days of paid annual leave to full-time employees.\n",
    "    Unused leave can be carried over to the next calendar year up to 10 days.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    The data platform runs nightly ETL jobs at 1 AM using Apache Airflow.\n",
    "    These jobs load sales data into the warehouse and refresh dashboards by 7 AM.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Employees can work from home up to 3 days per week with manager approval.\n",
    "    All remote work must comply with security and VPN policies.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Code changes must go through pull requests and be approved by at least one reviewer.\n",
    "    Continuous integration runs unit tests and static code analysis on every commit.\n",
    "    \"\"\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebb2cf",
   "metadata": {},
   "source": [
    "--> Above cell is for knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7f8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for i, doc in enumerate(documents):\n",
    "    chunks.append({\n",
    "        \"id\": i,\n",
    "        \"text\": doc.strip(),\n",
    "        \"metadata\": {\n",
    "            \"source\": f\"doc_{i}\"\n",
    "        }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30fbc1",
   "metadata": {},
   "source": [
    "--> Above cell is for chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daafa2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (4, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert chunk texts to embeddings\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "embeddings = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)  # (num_chunks, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82643ad1",
   "metadata": {},
   "source": [
    "--> Above cell is for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56144b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in index: 4\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Dimensions = size of embedding vector\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "# Create FAISS index (L2 index; we normalized embeddings so it behaves like cosine)\n",
    "index = faiss.IndexFlatIP(dim)  # IP = inner product (works well with normalized vectors)\n",
    "\n",
    "# Add vectors to index\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"Number of vectors in index:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb22b4",
   "metadata": {},
   "source": [
    "--> Above cell is for vector indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3a84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=2):\n",
    "    # 1. Embed the query\n",
    "    q_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "    # 2. Search in FAISS\n",
    "    scores, indices = index.search(q_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"chunk\": chunks[int(idx)]\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d6263",
   "metadata": {},
   "source": [
    " --> Above cell Embeds the query, Searches FAISS, Returns top-k chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e119a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: How many days of annual leave do employees get?\n",
      "\n",
      "Top retrieved chunks:\n",
      "\n",
      "Score: 0.798\n",
      "Source: doc_0\n",
      "Text:\n",
      " Our company offers 20 days of paid annual leave to full-time employees.\n",
      "    Unused leave can be carried over to the next calendar year up to 10 days.\n",
      "------------------------------------------------------------\n",
      "Score: 0.442\n",
      "Source: doc_2\n",
      "Text:\n",
      " Employees can work from home up to 3 days per week with manager approval.\n",
      "    All remote work must comply with security and VPN policies.\n",
      "------------------------------------------------------------\n",
      "\n",
      "QUESTION: How does employees work in this company?\n",
      "\n",
      "Top retrieved chunks:\n",
      "\n",
      "Score: 0.355\n",
      "Source: doc_2\n",
      "Text:\n",
      " Employees can work from home up to 3 days per week with manager approval.\n",
      "    All remote work must comply with security and VPN policies.\n",
      "------------------------------------------------------------\n",
      "Score: 0.321\n",
      "Source: doc_1\n",
      "Text:\n",
      " The data platform runs nightly ETL jobs at 1 AM using Apache Airflow.\n",
      "    These jobs load sales data into the warehouse and refresh dashboards by 7 AM.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def ask(question, top_k=2):\n",
    "    print(f\"\\nQUESTION: {question}\")\n",
    "    results = search(question, top_k=top_k)\n",
    "\n",
    "    print(\"\\nTop retrieved chunks:\\n\")\n",
    "    for r in results:\n",
    "        print(\"Score:\", round(r[\"score\"], 3))\n",
    "        print(\"Source:\", r[\"chunk\"][\"metadata\"][\"source\"])\n",
    "        print(\"Text:\\n\", r[\"chunk\"][\"text\"])\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ask(\"How many days of annual leave do employees get?\")\n",
    "    #ask(\"When do the ETL jobs run and which tool is used?\")\n",
    "    #ask(\"How does code review work in this company?\")\n",
    "    ask(\"How does employees work in this company?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a888120c",
   "metadata": {},
   "source": [
    " --> Above cell Rag retrival working or not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
